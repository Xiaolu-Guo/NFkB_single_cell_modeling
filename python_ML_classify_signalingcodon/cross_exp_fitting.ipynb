{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check xgboost version\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from typing import Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cross_val_predict(model, kfold, X, y ) -> Tuple[np.array, np.array, np.array]:\n",
    "\n",
    "    model_ = cp.deepcopy(model)\n",
    "    \n",
    "    no_classes = len(np.unique(y))\n",
    "    \n",
    "    actual_classes = np.empty([0], dtype=int)\n",
    "    actual_X_val = np.empty([0], dtype=int)\n",
    "    predicted_classes = np.empty([0], dtype=int)\n",
    "    predicted_proba = np.empty([0, no_classes]) \n",
    "\n",
    "    for train_ndx, test_ndx in kfold.split(X):\n",
    "\n",
    "        train_X, train_y, test_X, test_y = X[train_ndx], y[train_ndx], X[test_ndx], y[test_ndx]\n",
    "\n",
    "        actual_classes = np.append(actual_classes, test_y)\n",
    "        actual_X_val = np.append(actual_X_val,test_X)\n",
    "\n",
    "        model_.fit(train_X, train_y)\n",
    "        predicted_classes = np.append(predicted_classes, model_.predict(test_X))\n",
    "\n",
    "        try:\n",
    "            predicted_proba = np.append(predicted_proba, model_.predict_proba(test_X), axis=0)\n",
    "        except:\n",
    "            predicted_proba = np.append(predicted_proba, np.zeros((len(test_X), no_classes), dtype=float), axis=0)\n",
    "\n",
    "    return actual_classes, predicted_classes, predicted_proba, actual_X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual_classes, predicted_classes, sorted_labels):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes, labels=sorted_labels)\n",
    "    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "[[605  12   4   1  10]\n",
      " [ 23 387  40  96  41]\n",
      " [  6  65 158  63  74]\n",
      " [  3 147  41 185  36]\n",
      " [  2  44  47  20 435]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ade\n",
      "[[531  30   9   8  54]\n",
      " [ 39 329  40 108  71]\n",
      " [ 27 102 106  65  66]\n",
      " [ 15 175  45 147  30]\n",
      " [ 37 101  31  18 361]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/admin/anaconda3/envs/envpy311/lib/python3.11/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling\n",
      "[[579   7   2   7   5]\n",
      " [ 27 378  83  88  24]\n",
      " [  6  87 328  94  85]\n",
      " [ 19  77  94 380  30]\n",
      " [  3  29  82  18 468]]\n"
     ]
    }
   ],
   "source": [
    "# try cross validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "data_name_vec = ['Fitting', 'Ade', 'Sampling']\n",
    "for data_name in data_name_vec :\n",
    "    # data_name = 'Ade'\n",
    "    XFileName = 'X_codon_stim_' + data_name + '.csv'\n",
    "    yFileName = 'y_codon_stim_' + data_name + '.csv'\n",
    "    SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "    X = read_csv(XFileName,header = None)\n",
    "    #print(X.shape)            \n",
    "    y = read_csv(yFileName,header = None)\n",
    "    #print(y.shape)\n",
    "    kfold = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "\n",
    "    actual_classes, predicted_classes, _ , actual_X_val= cross_val_predict(model, kfold, X.to_numpy(), y.to_numpy())\n",
    "    # plot_confusion_matrix(actual_classes, predicted_classes, [\"TNF\", \"Pam3CSK\", \"CpG\", \"LPS\", \"PolyIC\"])\n",
    "    #print(actual_classes,predicted_classes)\n",
    "    confu_mat = confusion_matrix(actual_classes,predicted_classes)\n",
    "    print(data_name)\n",
    "    print(confu_mat)\n",
    "    #accuracy = model.score(actual_X_val, predicted_classes)\n",
    "    #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2545, 6)\n",
      "(2545, 1)\n",
      "2532    4\n",
      "1637    3\n",
      "2393    4\n",
      "1628    3\n",
      "2095    4\n",
      "       ..\n",
      "960     1\n",
      "905     1\n",
      "1096    1\n",
      "235     0\n",
      "1061    1\n",
      "Name: 0, Length: 1705, dtype: int64\n",
      "(840,)\n",
      "(2545, 6)\n",
      "(2545, 1)\n",
      "0.5845238095238096\n",
      "[[172   6   2   4  17]\n",
      " [ 13 103  16  46  15]\n",
      " [  7  26  51  29  27]\n",
      " [  2  55  13  53  12]\n",
      " [ 15  30   5   9 112]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Ade'\n",
    "XFileName = 'X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Fitting'\n",
    "XFileName_2 = 'X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)\n",
    "\n",
    "#y_pred_2 = model.predict(X_2)\n",
    "\n",
    "#confu_mat = confusion_matrix(y_2,y_pred_2)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "#accuracy = model.score(X_2, y_2)\n",
    "#print(accuracy)\n",
    "#print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2545, 6)\n",
      "(2545, 1)\n",
      "2532    4\n",
      "1637    3\n",
      "2393    4\n",
      "1628    3\n",
      "2095    4\n",
      "       ..\n",
      "960     1\n",
      "905     1\n",
      "1096    1\n",
      "235     0\n",
      "1061    1\n",
      "Name: 0, Length: 1705, dtype: int64\n",
      "(2545, 6)\n",
      "(2545, 1)\n",
      "0.7083333333333334\n",
      "[[195   5   1   0   0]\n",
      " [  8 127  12  33  13]\n",
      " [  2  22  71  23  22]\n",
      " [  1  48  13  63  10]\n",
      " [  1  13  14   4 139]]\n"
     ]
    }
   ],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "# linear regression feature importance\n",
    "# from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for feature importance on a classification problem\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "\n",
    "# 'Fitting' 'Ade' 'Sampling'\n",
    "data_name = 'Fitting'\n",
    "XFileName = 'X_codon_stim_' + data_name + '.csv'\n",
    "yFileName = 'y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X = read_csv(XFileName,header = None)\n",
    "print(X.shape)            \n",
    "y = read_csv(yFileName,header = None)\n",
    "print(y.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "\n",
    "#print(y_train)\n",
    "#print(y)\n",
    "# define the model\n",
    "# define dataset\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model\n",
    "y_train = y_train.iloc[:, 0]\n",
    "print(y_train)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# import fitting data:\n",
    "\n",
    "data_name_2 = 'Ade'\n",
    "XFileName_2 = 'X_codon_stim_' + data_name + '.csv'\n",
    "yFileName_2 = 'y_codon_stim_' + data_name + '.csv'\n",
    "SaveFileName_2 = 'XGBClassification_' + data_name + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_only_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "            # SaveFileName = 'XGBRegression_with_randompara_' + FeatureLig + '_' + Ligand + '_' + DoseSymbol + '.csv'\n",
    "\n",
    "X_2 = read_csv(XFileName,header = None)\n",
    "print(X_2.shape)            \n",
    "y_2 = read_csv(yFileName,header = None)\n",
    "print(y_2.shape)\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=3, n_informative=2, n_redundant=1, random_state=1, n_classes = 2)\n",
    "# print(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, y_2, test_size=0.33, random_state=1)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "confu_mat = confusion_matrix(y_test,y_pred)\n",
    "# np.savetxt(SaveFileName,confu_mat,  delimiter=\",\")  #fmt = '%d',\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "print(confu_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envpy311",
   "language": "python",
   "name": "envpy311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
